\documentclass[a4paper, 10pt]{article}
\usepackage{../CEDT-Homework-style}

\usepackage{amsmath}
\allowdisplaybreaks

\setlength{\headheight}{14.49998pt}

\begin{document}
\subject[2110573 - Pattern Recognition]
\hwtitle{1}{}{Week 1 - Clustering and Regression}{Patthadon Phengpinij}{ChatGPT}


% ================================================================================ %
\section{Metrics}
% ================================================================================ %

In a population where the amount of cats is equal to the amount of dogs.
Considering the following classification results from a classifier.

\[
\renewcommand{\arraystretch}{1.3}
\begin{array}{|c|c|c|}
    \hline
    \text{Model A} & \text{Predictied dog} & \text{Predictied cat} \\
    \hline\hline
    \text{Actual dog} & 30 & 20 \\
    \hline
    \text{Actual cat} & 10 & 40 \\
    \hline\hline
\end{array}
\]

% ================================================================================ %
%                                    Problem T01                                   %
% ================================================================================ %
\begin{Tproblem}
What is the accuracy of Model A?
\end{Tproblem}

\begin{solution}
First, assume that we consider dogs as `class 0' (negative) and cats as `class 1' (positive).
From the confusion matrix above, we can identify the following values:
\begin{itemize}
    \item True Positives (TP): 40 (Actual cat predicted as cat)
    \item True Negatives (TN): 30 (Actual dog predicted as dog)
    \item False Positives (FP): 10 (Actual cat predicted as dog)
    \item False Negatives (FN): 20 (Actual dog predicted as cat)
\end{itemize}

The formula for accuracy is given by:
\begin{align*}
    Accuracy &= \frac{TP + TN}{TP + TN + FP + FN} \\
    &= \frac{40 + 30}{40 + 30 + 10 + 20} \\
    &= \frac{70}{100} \\
    Accuracy &= 0.7
\end{align*}

Thus, from the calculation above, the \textbf{Accuracy} of Model A is \( \boxed{ 0.7 \text{ or } 70\% } \).
\end{solution}
% ================================================================================ %

\newpage

% ================================================================================ %
%                                    Problem T02                                   %
% ================================================================================ %
\begin{Tproblem}
Consider cats as `class 1' (positive) and dogs as `class 0' (negative),
calculate the precision, recall, and F1.
\end{Tproblem}

\begin{solution}
The situation is the same as in Problem T01, where we have all TP, TN, FP, and FN values identified.
Now, we can calculate precision, recall, and F1 score using the following formulas:
\begin{align*}
    Precision &= \frac{TP}{TP + FP} \\
    Recall &= \frac{TP}{TP + FN} \\
    F1 &= \frac{2TP}{2TP + FP + FN}
\end{align*}

Substituting the values we have:
\begin{align*}
    Precision &= \frac{40}{40 + 10} \\
    &= \frac{40}{50} \\
    Precision &= 0.8 \\
    Recall &= \frac{40}{40 + 20} \\
    &= \frac{40}{60} \\
    Recall &\approx 0.6667 \\
    F1 &= \frac{(2 \times 40)}{(2 \times 40) + 10 + 20} \\
    &= \frac{80}{80 + 30} \\
    &= \frac{80}{110} \\
    F1 &\approx 0.7273
\end{align*}

Thus, the calculated metrics are:
\begin{itemize}
    \item \textbf{Precision:} \( \boxed{ 0.8 } \)
    \item \textbf{Recall:} \( \boxed{ \approx 0.6667 } \)
    \item \textbf{F1 Score:} \( \boxed{ \approx 0.7273 } \)
\end{itemize}
\end{solution}
% ================================================================================ %

\newpage

% ================================================================================ %
%                                    Problem T03                                   %
% ================================================================================ %
\begin{Tproblem}
Consider class cat as `class 0' and class dog as `class 1',
calculate the precision, recall, and F1.
\end{Tproblem}

\begin{solution}
Switching the classes means we need to redefine TP, TN, FP, and FN:
\begin{itemize}
    \item True Positives (TP): 30 (Actual dog predicted as dog)
    \item True Negatives (TN): 40 (Actual cat predicted as cat)
    \item False Positives (FP): 20 (Actual dog predicted as cat)
    \item False Negatives (FN): 10 (Actual cat predicted as dog)
\end{itemize}

Now, we can calculate precision, recall, and F1 score using the same formulas:
\begin{align*}
    Precision &= \frac{TP}{TP + FP} \\
    Recall &= \frac{TP}{TP + FN} \\
    F1 &= \frac{2TP}{2TP + FP + FN}
\end{align*}

Substituting the new values:
\begin{align*}
    Precision &= \frac{30}{30 + 20} \\
    &= \frac{30}{50} \\
    Precision &= 0.6 \\
    Recall &= \frac{30}{30 + 10} \\
    &= \frac{30}{40} \\
    Recall &= 0.75 \\
    F1 &= \frac{(2 \times 30)}{(2 \times 30) + 20 + 10} \\
    &= \frac{60}{60 + 30} \\
    &= \frac{60}{90} \\
    F1 &\approx 0.6667
\end{align*}

Thus, the calculated metrics are:
\begin{itemize}
    \item \textbf{Precision:} \( \boxed{ 0.6 } \)
    \item \textbf{Recall:} \( \boxed{ 0.75 } \)
    \item \textbf{F1 Score:} \( \boxed{ \approx 0.6667 } \)
\end{itemize}
\end{solution}
% ================================================================================ %

\paragraph{\textit{Note:}}
It is important to specify the `positive' class when you calculate precision, recall, and F1.
If there are more than two classes, it is usually done in a one versus-all setting where one class is
considered positive and the rest of the classes are considered negative.

\newpage

% ================================================================================ %
%                                    Problem T04                                   %
% ================================================================================ %
\begin{Tproblem}
Now consider a lopsided population where there are 80\% cats.
What is the accuracy of Model A? Using dog as the positive class, what is the precision, recall, and F1?
Explain how and why these numbers change (or does not change) from the previous questions.
\end{Tproblem}

\begin{solution}
In a lopsided population where 80\% are cats and 20\% are dogs, we need to adjust the confusion matrix accordingly.
Assuming the same classification performance as Model A, we can scale the confusion matrix based on the new population distribution.
\[
\renewcommand{\arraystretch}{1.3}
\begin{array}{|c|c|c|}
    \hline
    \text{Model A} & \text{Predictied dog} & \text{Predictied cat} \\
    \hline\hline
    \text{Actual dog} & 12 & 8 \\
    \hline
    \text{Actual cat} & 16 & 64 \\
    \hline\hline
\end{array}
\]

Explaining the changes:
\begin{itemize}
    \item True Positives (TP): 12 (Actual dog predicted as dog)
    \item True Negatives (TN): 64 (Actual cat predicted as cat)
    \item False Positives (FP): 16 (Actual cat predicted as dog)
    \item False Negatives (FN): 8 (Actual dog predicted as cat)
\end{itemize}

This new confusion matrix came from
scaling down the previous counts by a factor of 0.4 for dogs (since the dog population decreased from 50 to 20)
and scaling up by a factor of 1.6 for cats (since the cat population increased from 50 to 80).

Next, we calculate the accuracy, precision, recall, and F1 score:
\[ Accuracy = \frac{TP + TN}{TP + TN + FP + FN} = \frac{12 + 64}{12 + 64 + 16 + 8} = \frac{76}{100} = 0.76 \]
\[ Precision = \frac{TP}{TP + FP} = \frac{12}{12 + 16} = \frac{12}{28} \approx 0.4286 \]
\[ Recall = \frac{TP}{TP + FN} = \frac{12}{12 + 8} = \frac{12}{20} = 0.6 \]
\[ F1 = \frac{(2 \times 12)}{(2 \times 12) + 16 + 8} = \frac{24}{24 + 24} = \frac{24}{48} = 0.5 \]

Thus, the calculated metrics in the lopsided population are:
\begin{itemize}
    \item \textbf{Accuracy:} \( \boxed{ 0.76 \text{ or } 76\% } \) \\
    The accuracy has increased from 0.7 to 0.76 because the model correctly classifies
    a larger proportion of the majority class (cats).

    \item \textbf{Precision:} \( \boxed{ \approx 0.4286 } \) \\
    Precision has decreased significantly because the number of false positives (cats predicted as dogs)
    has increased relative to true positives.

    \item \textbf{Recall:} \( \boxed{ 0.6 } \) \\
    Recall has decreased slightly from 0.6667 to 0.6, indicating that the model is missing more actual dogs.

    \item \textbf{F1 Score:} \( \boxed{ 0.5 } \) \\
    The F1 score has decreased from approximately 0.7273 to 0.5,
    reflecting the trade-off between precision and recall in this lopsided population.
\end{itemize}
\end{solution}
% ================================================================================ %

\newpage

% ================================================================================ %
%                                   Problem OT01                                   %
% ================================================================================ %
\begin{OTproblem}
Consider the equations for accuracy and F1
\[
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\]
\[
F1 = \frac{2TP}{2TP + FP + FN}
\]
When will accuracy be equal, greater, or less than F1?
\end{OTproblem}

\begin{solution}
To determine when accuracy is equal to, greater than, or less than F1, we can set up the equations and analyze them.
Setting accuracy equal to F1:
\begin{align*}
    Accuracy &= F1 \\
    \frac{TP + TN}{TP + TN + FP + FN} &= \frac{2TP}{2TP + FP + FN} \\
    (TP + TN)(2TP + FP + FN) &= (2TP)(TP + TN + FP + FN)
\end{align*}

Expanding both sides, continuing the simplification, we get:
\begin{align*}
    0 &= (TP - TN)(FP + FN)
\end{align*}

From the final equation, we can see that \textbf{accuracy equals F1} when either:
\begin{itemize}
    \item \( TP = TN \) (the number of true positives equals the number of true negatives), or
    \item \( FP + FN = 0 \) (since both FP and FN cannot be negative, there are no false positives or false negatives,
    meaning \textbf{perfect classification}).
\end{itemize}

Next, we analyze when accuracy is greater than F1:
\begin{align*}
    Accuracy &> F1 \\
    \frac{TP + TN}{TP + TN + FP + FN} &> \frac{2TP}{2TP + FP + FN}
\end{align*}

Following similar steps as above, we got:
\begin{align*}
    0 &> (TP - TN)(FP + FN)
\end{align*}

Since \( FP + FN \) is always non-negative, assume imperfect classification, for the product to be negative, we must have:
\begin{align*}
    TP - TN &< 0 \\
    TP &< TN
\end{align*}

Thus, we find that \textbf{accuracy is greater than F1} when:
\[ TP < TN \text{ (the number of true positives is less than the number of true negatives)} \]

On the other hand, following similar steps, we find that \textbf{accuracy is less than F1} when:
\[ TP > TN \text{ (the number of true positives is greater than the number of true negatives)} \]

Therefore, summarizing the results:
\begin{itemize}
    \item \( Accuracy = F1 \) when \( TP = TN \) or \( FP + FN = 0 \) (perfect classification).
    \item \( Accuracy > F1 \) when \( TP < TN \) and \( FP + FN > 0 \) (imperfect classification).
    \item \( Accuracy < F1 \) when \( TP > TN \) and \( FP + FN > 0 \) (imperfect classification).
\end{itemize}
\end{solution}
% ================================================================================ %

\newpage

% ================================================================================ %
\section{Clustering}
% ================================================================================ %

Recall from lecture that K-means has two main steps: the points assignment step, and the mean update step.
After the initialization of the centroids, we assign each data point to a centroid.
Then, each centroids are updated by re-estimating the means.

\par Concretely, if we are given \( N \) data points, \( x_1 \), \( x_2 \), ..., \( x_N \), and we would like to form K clusters.
We do the following;

\begin{enumerate}
    \item \textbf{Initialization:} Pick K random data points as K centroid locations \( c_1 \), \( c_2 \), ..., \( c_K \).
    \item \textbf{Assign:} For each data point k, find the closest centroid. Assign that data point to the centroid.
    The distance used is typically Euclidean distance.
    \item \textbf{Update:} For each centroid, calculate the mean from the data points assigned to it.
    \item \textbf{Repeat:} Repeat step 2 and 3 until the centroids stop changing (convergence).
\end{enumerate}

\par\noindent Given the following data points in x-y coordinates (2 dimensional)

\[
\renewcommand{\arraystretch}{1.3}
\begin{array}{|c|c|}
    \hline
    x & y \\
    \hline
    1 & 2 \\
    3 & 3 \\
    2 & 2 \\
    8 & 6 \\
    7 & 8 \\
    6 & 7 \\
    -3 & -3 \\
    -2 & -4 \\
    -7 & -7 \\
    \hline
\end{array}
\]

\begin{center}
    \includegraphics[width=0.4\textwidth]{images/clustering_data.png}
\end{center}


% ================================================================================ %
%                                    Problem T05                                   %
% ================================================================================ %
\begin{Tproblem}
If the starting points are \( (3, 3) \), \( (2, 2) \), and \( (-3, -3) \).
Describe each assign and update step. What are the points assigned?
What are the updated centroids? You may do this calculation by hand or write a program to do it.
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                    Problem T06                                   %
% ================================================================================ %
\begin{Tproblem}
If the starting points are \( (-3, -3) \), \( (2, 2) \), and \( (-7, -7) \), what happens?
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                    Problem T07                                   %
% ================================================================================ %
\begin{Tproblem}
Between the two starting set of points in the previous two questions, which one do you think is better?
How would you measure the `goodness' quality of a set of starting points?
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                   Problem OT02                                   %
% ================================================================================ %
\begin{OTproblem}
What would be the best K for this question? Describe your reasoning.
\end{OTproblem}

\begin{solution}
The solution for the \textbf{OT} problem goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
\section{My heart will go on}
% ================================================================================ %

\paragraph{\textit{Note:}}
Many parts of this exercise are adapted from Kaggle Python Tutorial on Machine Learning

\begin{center}
    \includegraphics[width=0.4\textwidth]{images/my_heart_will_go_on.png}
\end{center}

\noindent In this part of the exercise we will work on the Titanic dataset provided by Kaggle.
The Titanic dataset contains information of the passengers boarding the Titanic on its final voyage.
We will work on predicting whether a given passenger will survive the trip.

Let's launch Jupyter and start coding!

We start by importing the data using Pandas.

\begin{codingbox}
train_url = "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv"
train = pd.read_csv(train_url) #training set

test_url = "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv"
test = pd.read_csv(test_url) #test set
\end{codingbox}

Both train and test are dataframes.
Use the function \texttt{train.head()} and \texttt{train.tail()} to explore the data.
What do you see?

Use the function \texttt{describe()} to get a better understanding of the data.
You can read the meaning of the data fields at \href{https://www.kaggle.com/c/titanic/data}{https://www.kaggle.com/c/titanic/data}.

Looking at the data, you will notice a lot of missing values.
For example, some age is NaN. This is normal for real world data to have some missing values.
There are several ways to handle missing values.
The simplest is to throw away any rows that have missing values.
However, this usually reduce the amount of training data you have.
Another method is to guess what the missing value should be.
The simplest guess is to use the Median or Mode of the data.
For this exercise we will proceed with this.

% ================================================================================ %
%                                    Problem T08                                   %
% ================================================================================ %
\begin{Tproblem}
What is the median age of the training set?
You can easily modify the age in the dataframe by:

\begin{codingbox}
train["Age"] = train["Age"].fillna(train["Age"].median())
\end{codingbox}
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %

Note that you need to modify the code above a bit to fill with \texttt{mode()}
because \texttt{mode()} returns a series rather than a single value.

% ================================================================================ %
%                                    Problem T09                                   %
% ================================================================================ %
\begin{Tproblem}
Somefields like `Embarked' are categorical.
They need to be converted to numbers first.
We will represent S with 0, C with 1, and Q with 2. What is the mode of Embarked?
Fill the missing values with the mode.
You can set the value of Embarked easily with the following command.

\begin{codingbox}
train.loc[train["Embarked"] == "S", "Embarked"] = 0
\end{codingbox}
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %

Do the same for Sex.

% ================================================================================ %
%                                    Problem T10                                   %
% ================================================================================ %
\begin{Tproblem}
Write a logistic regression classifier using gradient descent as learned in class.
Use PClass, Sex, Age, and Embarked as input features.
You can extract the features from Pandas to Numpy by:

\begin{codingbox}
data = np.array(train[["PClass","Sex","Age","Embarked"]].values)
\end{codingbox}

\noindent Check the datatype of each values in data, does it make sense?
You can force the data to be of any datatype by using the command:

\begin{codingbox}
data = np.array(train[["PClass","Sex","Age","Embarked"]].values, dtype = float)
\end{codingbox}
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %

When you evaluate the trained model on the test set, you will need to make a final decision.
Since logistic regression outputs a score between 0 and 1,
you will need to decide whether a score of 0.3 (or any other number) means the passenger survive or not.
For now, we will say if the score is greater than or equal to 0.5, the passenger survives.
If the score is lower than 0.5 the passenger will be dead.
This process is often called 'Thresholding.'
We will talk more about this process later in class.

To evaluate your results, we will use Kaggle.
Kaggle is a website that hosts many machine learning competitions.
Many companies put up their data as a problem for anyone to participate.
If you are looking for a task for your course project, Kaggle might be a good place to start.
You will need to make sure that your output is in line with the submission requirements of Kaggle:
a csv file with exactly 418 entries and two columns: PassengerId and Survived.
Then, use the code provided to make a new dataframe using \texttt{DataFrame()},
and create a csv file using \texttt{to\_csv()} method from Pandas.

To submit your prediction, you must first sign-up for an account on \href{Kaggle}{kaggle.com}.
Click participate to the competition at \href{https://www.kaggle.com/c/titanic}{https://www.kaggle.com/c/titanic} then submit your csv file for the score.

The output file should have two columns: the passengerId and a 0,1 decision (0 for dead, 1 for survive).
As shown below:

\begin{codingbox}
PassengerId,Survived
892,0
893,1
894,0
\end{codingbox}

% ================================================================================ %
%                                    Problem T11                                   %
% ================================================================================ %
\begin{Tproblem}
Submit a screenshot of your submission (with the scores).
Upload your code to courseville.
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                    Problem T12                                   %
% ================================================================================ %
\begin{Tproblem}
Try adding some higher order features to your training ( \( x^2_1 \), \( x_1 x_2 \), ...).
Does this model has better \textbf{accuracy on the training set}?
How does it perform on the \textbf{test set}?
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                    Problem T13                                   %
% ================================================================================ %
\begin{Tproblem}
What happens if you reduce the amount of features to just Sex and Age?
\end{Tproblem}

\begin{solution}
The solution goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                   Problem OT03                                   %
% ================================================================================ %
\begin{OTproblem}
We want to show that matrix inversion yields the same answer as the gradient descent method.
However, there is no closed form solution for logistic regression.
Thus, we will use normal linear regression instead.
Re-do the Titanic task as a regression problem by using linear regression.
Use the gradient descent method.
\end{OTproblem}

\begin{solution}
The solution for the \textbf{OT} problem goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                   Problem OT04                                   %
% ================================================================================ %
\begin{OTproblem}
Now try using matrix inversion instead.
However, are the weights learned from the two methods similar?
Report the Mean Squared Errors (MSE) of the difference between the two weights.
\end{OTproblem}

\begin{solution}
The solution for the \textbf{OT} problem goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
\section{Fun with matrix algebra [OPTIONAL]}
% ================================================================================ %

Prove the following statements.
All of them can be solved by first expanding out the matrix notation as a combination of their elements,
and then use the definitions of trace and matrix derivatives to help finish the proof.
For example, the \( (i,j) \) element of \( Y = AB \) is \( Y_{i, j} = \sum_m A_{i, m} B_{m, j} \).

% ================================================================================ %
%                                   Problem OT05                                   %
% ================================================================================ %
\begin{OTproblem}
\( \nabla_A tr \paren{AB} = B^T \)
\end{OTproblem}

\begin{solution}
The solution for the \textbf{OT} problem goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                   Problem OT06                                   %
% ================================================================================ %
\begin{OTproblem}
\( \nabla_{A^T} f(A) = \paren{ \nabla_A f(A) }^T \)
\end{OTproblem}

\begin{solution}
The solution for the \textbf{OT} problem goes here.
\end{solution}
% ================================================================================ %


% ================================================================================ %
%                                   Problem OT07                                   %
% ================================================================================ %
\begin{OTproblem}
\( \nabla_A tr \paren{AB A^T C} = CAB + C^T A B^T \)

\textit{Hint:} Try first solving the easier equation of \( \nabla_A tr \paren{BAC} = \paren{CB}^T = B^T C^T \)
\end{OTproblem}

\begin{solution}
The solution for the \textbf{OT} problem goes here.
\end{solution}
% ================================================================================ %


\end{document}